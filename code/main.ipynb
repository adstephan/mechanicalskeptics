{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PARENT_PATH = os.path.abspath(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(PARENT_PATH)\n",
    "\n",
    "from utils import flat_subreddits, subreddits\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_csv(f\"{PARENT_PATH}/data/processed/all_posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    \"generative ai\", \"aigc\", \"chatgpt\", \"gpt\", \"openai\", \"bard\", \"llm\", \"large language model\",\n",
    "    \"midjourney\", \"diffusion model\", \"stability ai\", \"ai\", \"artificial intelligence\",\n",
    "    \"artificial intelligence generated content\", \"dalle 2\", \"chatgpt\", \"chat gpt\", \"bing chat\",\n",
    "    \"bingchat\", \"perplexity ai\", \"perplexityai\", \"perplexity.ai\", \"perplexityask\", \"perplexity ask\",\n",
    "    \"dall-e-2\", \"dall-e 2\", \"dall-e2\", \"dall·e 2\", \"dall·e2\", \"dalle2\", \"dalle2\", \"(dalle 2)\",\n",
    "    \"dall-e\", \"dall·e\", \"(dalle)\", \"stable diffusion\", \"stablediffusion\", \"midjourney\", \"(mid journey)\",\n",
    "    \"imagen\", \"crayon\", \"dall-e-mini\", \"dall-e mini\", \"dall·e mini\", \"dall·e-mini\", \"dalle-mini\",\n",
    "    \"dallemini\", \"dalle mini\", \"dreamstudio\", \"copilot\", \"co-pilot\", \"gpt-4\", \"gpt4\", \"gpt 4\",\n",
    "    \"gpt-3.5\", \"gpt3.5\", \"gpt 3.5\", \"gpt-3\", \"gpt3\", \"gpt 3\", \"gpt-2\", \"gpt2\", \"(gpt 2)\", \"gemini\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts[\"all_text\"] = posts[\"title\"].str.lower() + \" \" + posts[\"selftext\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of AI-related posts: 179\n"
     ]
    }
   ],
   "source": [
    "# Add a column indicating if post contains any AI-related keyword\n",
    "# Compile regex pattern once for better performance\n",
    "pattern = re.compile(' | '.join(map(lambda x: f' {x} ', keywords)), re.IGNORECASE)\n",
    "\n",
    "# Create ai_related column using vectorized operations\n",
    "posts['ai_related'] = posts['all_text'].fillna('').apply(\n",
    "    lambda text: any(f' {kw} ' in f' {text.lower()} ' for kw in keywords)\n",
    ")\n",
    "\n",
    "# Print count of AI-related posts \n",
    "n_ai_posts = posts['ai_related'].sum()\n",
    "print(f\"Number of AI-related posts: {n_ai_posts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subreddits with AI-related posts before ChatGPT: 4\n",
      "Number of subreddits with AI-related posts after ChatGPT: 5\n",
      "\n",
      "Distribution of AI-related posts across subreddits before ChatGPT:\n",
      "subreddit\n",
      "AskALiberal         16\n",
      "centrist             8\n",
      "AskConservatives     7\n",
      "SocialDemocracy      6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of AI-related posts across subreddits after ChatGPT:\n",
      "subreddit\n",
      "AskALiberal         55\n",
      "AskConservatives    46\n",
      "centrist            28\n",
      "SocialDemocracy     12\n",
      "conservatives        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count number of unique subreddits with AI-related posts before/after ChatGPT\n",
    "chatgpt_date = pd.to_datetime('2022-11-30')\n",
    "posts['created_utc'] = pd.to_datetime(posts['created_utc'])\n",
    "\n",
    "# Before ChatGPT\n",
    "before_gpt = posts[\n",
    "    (posts['ai_related'] == True) & \n",
    "    (posts['created_utc'] < chatgpt_date)\n",
    "]\n",
    "before_subreddits = before_gpt['subreddit'].nunique()\n",
    "print(f\"Number of subreddits with AI-related posts before ChatGPT: {before_subreddits}\")\n",
    "\n",
    "# After ChatGPT \n",
    "after_gpt = posts[\n",
    "    (posts['ai_related'] == True) & \n",
    "    (posts['created_utc'] >= chatgpt_date)\n",
    "]\n",
    "after_subreddits = after_gpt['subreddit'].nunique()\n",
    "print(f\"Number of subreddits with AI-related posts after ChatGPT: {after_subreddits}\")\n",
    "\n",
    "# Show distribution before ChatGPT\n",
    "before_counts = before_gpt['subreddit'].value_counts()\n",
    "print(\"\\nDistribution of AI-related posts across subreddits before ChatGPT:\")\n",
    "print(before_counts)\n",
    "\n",
    "# Show distribution after ChatGPT\n",
    "after_counts = after_gpt['subreddit'].value_counts()\n",
    "print(\"\\nDistribution of AI-related posts across subreddits after ChatGPT:\")\n",
    "print(after_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
